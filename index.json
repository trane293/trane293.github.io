[{"authors":["admin"],"categories":null,"content":"I\u0026rsquo;m currently the Engineering Manager, Machine Learning (NLP) at BenchSci, a company which builds AI-powered platform called ASCEND for preclinical research in drug discovery. BenchSci caters to most large pharmaceutical companies, which happen to be our customers. At BenchSci, I lead a multi-disciplinary team named Text Enrichment team which is focused on developing NLP technologies for the ASCEND, including using Large Language Models (based off of GPT and BERT). Before that, I was the Director of Engineering (Machine Learning) at Xtract AI (known as Innovation Projects group within Patriot One Technologies). There I led and oversaw the development of Xtract AI\u0026rsquo;s product portfolio, consisting of three AI-enabled products in the space of video processing and natural language processing. Before this, I worked for over half a decade as a technical hands on engineer in data science as well as a researcher in various companies/institutes. I completed my Masters degree in Computing Science, and was a Research Assistant in Machine Learning and Medical Imaging at the Medical Image Analysis Laboratory (MIAL) under Prof. Ghassan Hamarneh at Simon Fraser University. I received a full scholarship to pursue my masters degree at SFU along with a special entrance scholarship. I later became an NSERC-CREATE Bioinformatics Fellow for the year 2018-2019 under the joint Bioinformatics Program between UBC-SFU.\nMy main interests lie in machine learning and deep learning, specifically for application towards medical imaging [1], [2], [3], computer vision [4], and natural language processing [5], [6]. I have hands on experience with a variety of different projects in both industry and academia, where I developed computer vision systems for autonomous cars [7], computer aided detection systems for mammography [3], [8] and brain MRI [9], handwritten signature verification system [10], and applied reinforcement learning algorithms to computer animation [11]. During my masters, I also worked as Machine Learning Researcher at the Division of Neurosurgery at Vancouver General Hospital. Apart from that, I was working part-time as a Consulting Software Engineer for Pluto Health Innovations to develop smart electronic health records (EHR) system for clinics by leveraging advances in natural language processing. Being an NSERC-CREATE Bioinformatics Fellow, I performed and presented thorough literature surveys in core bioinformatics [12], [13], as well as on the application of natural language processing methods in bioinformatics [14]. I have written short summaries for a number of seminal papers in medical image analysis, which are available here.\nBefore joining SFU for my masters, I worked as a Machine Learning Engineer at RadSupport Inc. alongside Stanford/Caltech alumni. I did my undergrad at DAV Institute of Engineering and Technology in Jalandhar, and received the INAE Mentoring of Engineering Students Fellowship to pursue undergraduate dissertation under Prof. Sushmita Mitra and Dr. B. Uma Shankar at ISI Kolkata.\nI wouldn\u0026rsquo;t be where I am without the support of some of the amazing mentors I\u0026rsquo;ve had in my life. I have had the privilege to be mentored by Dr. Jayasree Chakraborty and Dr. Abhishek Midya (Memorial Sloan Kettering Cancer Center) from early in my undergrad. I was mentored by Prof. Ghassan Hamarneh in performing ethical, high quality research that makes an impact in the world. Lately, I\u0026rsquo;ve been learning the art of business, sales, finance, executive leadership and relationship building through my mentor Dr. Cornell Pich. I\u0026rsquo;ve been helped tremendously by the advice from Dr. Justin Granek who helped me pave the path for my success at Xtract AI.\nPersonal Interests I\u0026rsquo;m passionate about racing (Formula 1, GT3, and IMSA Racing. I am an avid SimRacer, which is a form of realistic simulation racing on Assetto Corsa Competizione and iRacing. I\u0026rsquo;m big into culinary exploration - especially trying out vegetarian cuisines and developing my palette. I keep myself busy with some mechanical watch collection and their general admiration. I\u0026rsquo;m big into fitness (hiking, strength training, conditioning) and sports (volleyball).\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://trane293.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I\u0026rsquo;m currently the Engineering Manager, Machine Learning (NLP) at BenchSci, a company which builds AI-powered platform called ASCEND for preclinical research in drug discovery. BenchSci caters to most large pharmaceutical companies, which happen to be our customers. At BenchSci, I lead a multi-disciplinary team named Text Enrichment team which is focused on developing NLP technologies for the ASCEND, including using Large Language Models (based off of GPT and BERT). Before that, I was the Director of Engineering (Machine Learning) at Xtract AI (known as Innovation Projects group within Patriot One Technologies).","tags":null,"title":"Anmol Sharma","type":"authors"},{"authors":["Anmol Sharma","Ghassan Hamarneh"],"categories":null,"content":"","date":1577577600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577577600,"objectID":"9f068fac3c671ff339b13200e1e8fa94","permalink":"https://trane293.github.io/publication/mmgan_arxiv/","publishdate":"2019-04-27T00:00:00Z","relpermalink":"/publication/mmgan_arxiv/","section":"publication","summary":"Magnetic resonance imaging (MRI) is being increasingly utilized to assess, diagnose, and plan treatment for a variety of diseases. The ability to visualize tissue in varied contrasts in the form of MR pulse sequences in a single scan provides valuable insights to physicians, as well as enabling automated systems performing downstream analysis. However many issues like prohibitive scan time, image corruption, different acquisition protocols, or allergies to certain contrast materials may hinder the process of acquiring multiple sequences for a patient. This poses challenges to both physicians and automated systems since complementary information provided by the missing sequences is lost. In this paper, we propose a variant of generative adversarial network (GAN) capable of leveraging redundant information contained within multiple available sequences in order to generate one or more missing sequences for a patient scan. The proposed network is designed as a multi-input, multi-output network which combines information from all the available pulse sequences, implicitly infers which sequences are missing, and synthesizes the missing ones in a single forward pass. We demonstrate and validate our method on two brain MRI datasets each with four sequences, and show the applicability of the proposed method in simultaneously synthesizing all missing sequences in any possible scenario where either one, two, or three of the four sequences may be missing. We compare our approach with competing unimodal and multi-modal methods, and show that we outperform both quantitatively and qualitatively.","tags":["mri","deep learning","generative adversarial networks","medical image analysis","computer vision"],"title":"Missing MRI Pulse Sequence Synthesis using Multi-Modal Generative Adversarial Network","type":"publication"},{"authors":["Ben Cardoen","Hanene Ben Yedder","Anmol Sharma","Keng C Chou","Ivan Robert Nabi","Ghassan Hamarneh"],"categories":null,"content":"","date":1577232000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577232000,"objectID":"7f0d4f05a9fb8fc8293008362388a988","permalink":"https://trane293.github.io/publication/ergo_tmi/","publishdate":"2019-04-27T00:00:00Z","relpermalink":"/publication/ergo_tmi/","section":"publication","summary":"Single molecule localization microscopy (SMLM) allows unprecedented insight into the three-dimensional organization of proteins at the nanometer scale. The combination of minimal invasive cell imaging with high resolution positions SMLM at the forefront of scientific discovery in cancer, infectious, and degenerative diseases. By stochastic temporal and spatial separation of light emissions from fluorescent labelled proteins, SMLM is capable of nanometer scale reconstruction of cellular structures. Precise localization of proteins in 3D astigmatic SMLM is dependent on parameter sensitive preprocessing steps to select regions of interest. With SMLM acquisition highly variable over time, it is non-trivial to find an optimal static parameter configuration. The high emitter density required for reconstruction of complex protein structures can compromise accuracy and introduce artifacts. To address these problems, we introduce two modular auto-tuning pre-processing methods: adaptive signal detection and learned recurrent signal density estimation that can leverage the information stored in the sequence of frames that compose the SMLM acquisition process. We show empirically that our contributions improve accuracy, precision and recall with respect to the state of the art. Both modules auto-tune their hyper-parameters to reduce the parameter space for practitioners, improve robustness and reproducibility, and are validated on a reference in silico dataset. Adaptive signal detection and density prediction can offer a practitioner, in addition to informed localization, a tool to tune acquisition parameters ensuring improved reconstruction of the underlying protein complex. We illustrate the challenges faced by practitioners in applying SMLM algorithms on real world data markedly different from the data used in development and show how ERGO can be run on new datasets without retraining while motivating the need for robust transfer learning in SMLM.","tags":["deep learning","super resolution microscopy","medical image analysis","long short term memory networks"],"title":"ERGO: Efficient Recurrent Graph Optimized Emitter Density Estimation in Single Molecule Localization Microscopy","type":"publication"},{"authors":["Anmol Sharma"],"categories":null,"content":" ","date":1558346400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1558346400,"objectID":"b069a4e3ee800a11c021273872e8a72d","permalink":"https://trane293.github.io/talk/mmgan-ubc/","publishdate":"2019-05-20T10:00:00Z","relpermalink":"/talk/mmgan-ubc/","section":"talk","summary":"Invited to present my research in which we proposed a multi-input, multi-output generative adversarial network (GAN) called MM-GAN as a poster presentation.","tags":["deep learning","generative adversarial networks","medical imaging","mri","invited"],"title":"[Invited Talk] MM-GAN: Multi-Modal Generative Adversarial Network for Missing MRI Pulse Sequence Synthesis","type":"talk"},{"authors":["Anmol Sharma","Ghassan Hamarneh"],"categories":null,"content":" ","date":1556724600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556724600,"objectID":"7ad35c4203bedf6f3a6c44d50de03597","permalink":"https://trane293.github.io/talk/mmgan-vin/","publishdate":"2019-05-01T15:30:00Z","relpermalink":"/talk/mmgan-vin/","section":"talk","summary":"Invited to present my research in which we proposed a multi-input, multi-output generative adversarial network (GAN) called MM-GAN.","tags":["deep learning","generative adversarial networks","medical imaging","mri","invited"],"title":"[Invited Talk] Missing MRI Pulse Sequence Synthesis using Multi-Modal Generative Adversarial Network","type":"talk"},{"authors":["Anmol Sharma"],"categories":null,"content":" ","date":1556206200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556206200,"objectID":"008c8f05f3e0722e43028a8cf19f6f87","permalink":"https://trane293.github.io/talk/outlier-iclr2019/","publishdate":"2019-04-25T15:30:00Z","relpermalink":"/talk/outlier-iclr2019/","section":"talk","summary":"Presented an interesting paper from ICLR 2019 that performs out-of-distribution sample detection using a simple framework.","tags":["deep learning","computer vision","classification"],"title":"[Paper Presentation] Deep Anomaly Detection with Outlier Exposure","type":"talk"},{"authors":["Anmol Sharma"],"categories":null,"content":" ","date":1542726000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542726000,"objectID":"e368ded84774369902f4eaf1f74ad3d9","permalink":"https://trane293.github.io/talk/nlp-structural-modelling/","publishdate":"2018-11-20T15:00:00Z","relpermalink":"/talk/nlp-structural-modelling/","section":"talk","summary":"Presenting a highly scientific paper in a way that high school students can understand. The paper is a state-of-art method that uses natural language processing based approach towards structural modelling of proteins.","tags":["deep learning","natural language processing","bioinformatics"],"title":"[Paper Presentation] Natural Language Processing in Text Mining for Structural Modeling of Protien Complexes","type":"talk"},{"authors":["Anmol Sharma"],"categories":null,"content":" ","date":1540998000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540998000,"objectID":"e49fa5186e2ab3e87c407cea9f90896d","permalink":"https://trane293.github.io/talk/shape-reg/","publishdate":"2018-10-31T15:00:00Z","relpermalink":"/talk/shape-reg/","section":"talk","summary":"This talk covers a classical method for shape registration using approaches from information theory and deformations.","tags":["machine learning","shape registration","computer vision","medical image analysis"],"title":"[Paper Presentation] Shape Registration in Implicit Spaces Using Information Theory and Free Form Deformations","type":"talk"},{"authors":["Anmol Sharma"],"categories":null,"content":" ","date":1539183600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539183600,"objectID":"ca24d43c1def903e77f858ef92ef5bab","permalink":"https://trane293.github.io/talk/live-wire/","publishdate":"2018-10-10T15:00:00Z","relpermalink":"/talk/live-wire/","section":"talk","summary":"Paper presentation for the Live-Wire segmentation method, that was famously used in Adobe Photoshop.","tags":["linear algebra","optimization","mri","medical image analysis","computer vision"],"title":"[Paper Presentation] Interactive Live-Wire Boundary Extraction","type":"talk"},{"authors":["Anmol Sharma"],"categories":null,"content":" ","date":1537455600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537455600,"objectID":"6bb1b381a7d56250a6f812eccb10fe77","permalink":"https://trane293.github.io/talk/text-mining/","publishdate":"2018-09-20T15:00:00Z","relpermalink":"/talk/text-mining/","section":"talk","summary":"Literature survey on the uses of text mining and natural language processing methods in bioinformatics.","tags":["deep learning","natural language processing","bioinformatics"],"title":"Knowledge Extraction and Text Mining in Bioinformatics","type":"talk"},{"authors":["Anmol Sharma"],"categories":null,"content":" ","date":1534777200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534777200,"objectID":"84080508ff4f701abb3bfe9a28282a39","permalink":"https://trane293.github.io/talk/canu/","publishdate":"2018-08-20T15:00:00Z","relpermalink":"/talk/canu/","section":"talk","summary":"Presented a state-of-art long-read assembly pipeline 'Canu', which builds upon many existing methods.","tags":["bioinformatics","long-read assembly","sequencing","ngs-sequencing"],"title":"[Paper Presentation] Canu: Scalable and Accurate Long-Read Assembly via Adaptive k-mer Weighting and Repeat Separation","type":"talk"},{"authors":["Anmol Sharma"],"categories":null,"content":" ","date":1531400400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531400400,"objectID":"f2ba1438762fa0c9516335bad38ec72e","permalink":"https://trane293.github.io/talk/missing_pulse_sequences/","publishdate":"2018-07-12T13:00:00Z","relpermalink":"/talk/missing_pulse_sequences/","section":"talk","summary":"A talk regarding the current state-of-art in handling missing inputs for segmentation or classification problems.","tags":["deep learning","machine learning","mri","medical image analysis","computer vision"],"title":"Dealing with Missing Modalities in Medical Images What's Missing?","type":"talk"},{"authors":["Subhasis Banerjee","Sushmita Mitra","Anmol Sharma","B. Uma Shankar"],"categories":null,"content":"","date":1529452800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1529452800,"objectID":"07dc0a1be52d03b680380f0a98528f02","permalink":"https://trane293.github.io/publication/cade-arxiv/","publishdate":"2018-06-20T00:00:00Z","relpermalink":"/publication/cade-arxiv/","section":"publication","summary":"Inspired by the success of Convolutional Neural Networks (CNN), we develop a novel Computer Aided Detection (CADe) system using CNN for Glioblastoma Multiforme (GBM) detection and segmentation from multi channel MRI data. A two-stage approach first identifies the presence of GBM. This is followed by a GBM localization in each \"abnormal\" MR slice. As part of the CADe system, two CNN architectures viz. Classification CNN (C-CNN) and Detection CNN (D-CNN) are employed. The CADe system considers MRI data consisting of four sequences (T1, T1c, T2, and T2FLAIR) as input, and automatically generates the bounding boxes encompassing the tumor regions in each slice which is deemed abnormal. Experimental results demonstrate that the proposed CADe system, when used as a preliminary step before segmentation, can allow improved delineation of tumor region while reducing false positives arising in normal areas of the brain. The GrowCut method, employed for tumor segmentation, typically requires a foreground and background seed region for initialization. Here the algorithm is initialized with seeds automatically generated from the output of the proposed CADe system, thereby resulting in improved performance as compared to that using random seeds.","tags":["mri","deep learning","convolutional neural networks","medical image analysis","computer vision"],"title":"A CADe System for Gliomas in Brain MRI using Convolutional Neural Networks","type":"publication"},{"authors":["Saeid Asgari Taghanaki","Aicha Bentaieb","Anmol Sharma","S. Kevin Zhou","Yefeng Zheng","Bogdan Georgescu","Puneet Sharma","Sasa Grbic","Zhoubing Xu","Dorin Comaniciu","Ghassan Hamarneh"],"categories":null,"content":"","date":1523664000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1523664000,"objectID":"b5df8f1b5b7301714f8e9cdebae62147","permalink":"https://trane293.github.io/publication/sat-arxiv/","publishdate":"2018-04-14T00:00:00Z","relpermalink":"/publication/sat-arxiv/","section":"publication","summary":"Skip connections in deep networks have improved both segmentation and classification performance by facilitating the training of deeper network architectures, and reducing the risks for vanishing gradients. They equip encoder-decoder-like networks with richer feature representations, but at the cost of higher memory usage, computation, and possibly resulting in transferring non-discriminative feature maps. In this paper, we focus on improving skip connections used in segmentation networks (e.g., U-Net, V-Net, and The One Hundred Layers Tiramisu (DensNet) architectures). We propose light, learnable skip connections which learn to first select the most discriminative channels and then attend to the most discriminative regions of the selected feature maps. The output of the proposed skip connections is a unique feature map which not only reduces the memory usage and network parameters to a high extent, but also improves segmentation accuracy. We evaluate the proposed method on three different 2D and volumetric datasets and demonstrate that the proposed light, learnable skip connections can outperform the traditional heavy skip connections in terms of segmentation accuracy, memory usage, and number of network parameters.","tags":["convolutional neural networks","deep learning","medical image analysis","computer vision"],"title":"Select, Attend, and Transfer: Light, Learnable Skip Connections","type":"publication"},{"authors":null,"categories":null,"content":"Reinforcement learning (RL) have recently become the framework of choice to develop intelligent agents that can control various entities inside an environment through learning by trial and error. One such task where RL algorithms have been applied is to control simulated robots in a physics-based environment to achieve a set specific goal. These goals can be to run, walk, hop, grasp objects and so on depending on the environment. Recently due to a surge in deep learning (DL) research, RL algorithms have underwent a transformation where many algorithms were revived by utilizing DL methods in some of the internal workings of the RL algorithms. This class of algorithms were named as deep reinforcement learning (DRL). In this project we compare three different DRL algorithms with respect to their ability to control a simulated physics-based robot in an environment. More specifically, we compare Vanilla Policy Gradient (VPG) or REINFORCE, Trust Region Policy Optimization (TRPO) and Proximal Policy Optimization (PPO) algorithms in three different physics-based locomotion environments HalfCheetah-v2, Hopper-v2, and Walker2d-v2 defined in MuJoCo framework ordered by increasing difficulty. Through our experiments, we found the PPO exhibited better performance in all environments in terms of the total reward gained in an episode. VPG performed worse than PPO but better than TRPO due to its simplistic policy gradient approach, though the high variance in training process due to reliance on absolute episode rewards was evident from the experiments. We also observed the TRPO\u0026rsquo;s convergence is inherently highly predictable, stable, and mostly monotonically increasing, leading to good convergence guarantees but with increased training time.\n","date":1523232000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1523232000,"objectID":"f703b060081974bb162b96cc026712e2","permalink":"https://trane293.github.io/project/animation-rl-project/","publishdate":"2018-04-09T00:00:00Z","relpermalink":"/project/animation-rl-project/","section":"project","summary":"Comparison of various state-of-art reinforcement learning algorithms","tags":["deep learning","reinforcement learning","computer animation","physics-based locomotion"],"title":"Comparison of Deep Reinforcement Learning Algorithms for Learning Control Policies for Physics-based Locomotion Tasks","type":"project"},{"authors":["Anmol Sharma"],"categories":null,"content":" ","date":1521558000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1521558000,"objectID":"f7fcfc08a109047820ec84c45e61d10e","permalink":"https://trane293.github.io/talk/simbicon-genbicon/","publishdate":"2018-03-20T15:00:00Z","relpermalink":"/talk/simbicon-genbicon/","section":"talk","summary":"Presented two seminal models of physics-based walking, called SIMBICON and GENBICON. The course instructor KangKang Yin is the inventor of SIMBICON.","tags":["computer animation","physics-based control","pid controller"],"title":"[Paper Presentation] SIMBICON and GENBICON: Physics Based Control Models for Locomotion","type":"talk"},{"authors":["Anmol Sharma"],"categories":null,"content":" ","date":1521039600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1521039600,"objectID":"c09de1616846715035f24a159418d7bf","permalink":"https://trane293.github.io/talk/rl-tut/","publishdate":"2018-03-14T15:00:00Z","relpermalink":"/talk/rl-tut/","section":"talk","summary":"A mathematical, in-depth tutorial about reinforcement learning presented to the lab members. This was to facilitate members to take up RL methods and apply them to their respective problem areas, as well as for myself to understand RL in an in-depth way.","tags":["deep learning","reinforcement learning","computer vision","medical image analysis"],"title":"A Mathematical Tutorial on Reinforcement Learning","type":"talk"},{"authors":["Anmol Sharma"],"categories":null,"content":" ","date":1520866800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520866800,"objectID":"4e4d6db4e04277019da5e9105ca133a7","permalink":"https://trane293.github.io/talk/rl-ct/","publishdate":"2018-03-12T15:00:00Z","relpermalink":"/talk/rl-ct/","section":"talk","summary":"This talk covers the first known application of reinforcement learning agents for landmark detection in CT Scans in medical imaging.","tags":["deep learning","reinforcement learning","computer vision","medical image analysis"],"title":"[Paper Presentation] Multi-Scale Deep Reinforcement Learning for Real-Time 3D-Landmark Detection in CT Scans","type":"talk"},{"authors":null,"categories":null,"content":"Automatic evaluation metrics are fundamentally important for Machine Translation, allowing comparison of systems performance and efficient training. Current evaluation metrics fall into two classes: heuristic approaches, like BLEU or METEOR, and those using supervised learning trained on human judgment data. Evaluating a machine translation system using such heuristic metrics is faster, easier and cheaper as compared to human evaluations, which require trained bilingual evaluators. In this report, we present our approach to combine multiple automatic evaluation heuristics using machine learning and then compare the quality of translation of two different MT system. Our results show that while each heuristic approach can provide a valid comparison between two system, combining the techniques using our machine learning approach provides higher accuracy.\n","date":1513036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1513036800,"objectID":"3917d2f861f8e1949c57551eb2d0d551","permalink":"https://trane293.github.io/project/nlp-project/","publishdate":"2017-12-12T00:00:00Z","relpermalink":"/project/nlp-project/","section":"project","summary":"We propose a novel multi-metric voting scheme for evaluating machine translation systems.","tags":["machine learning","deep learning","natural language processing","machine translation","artificial neural networks","svm"],"title":"Evaluating Machine Translation Systems using Weighted Vote of Different Scoring Metrics","type":"project"},{"authors":null,"categories":null,"content":" ","date":1512432000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512432000,"objectID":"f3595097cbf942838d855b4d68ffee3d","permalink":"https://trane293.github.io/project/nlp-mini-project/","publishdate":"2017-12-05T00:00:00Z","relpermalink":"/project/nlp-mini-project/","section":"project","summary":"Re-imagining the problem of word segmentation as a sequence prediction problem, predicting spaces between words in a sequence.","tags":["deep learning","natural language processing","lstm","blstm"],"title":"Modelling Chinese Word Segmentation as Sequence to Sequence Prediction Problem","type":"project"},{"authors":null,"categories":null,"content":"In this paper we investigate the problem of predicting survival time (in days) for patients diagnosed with high grade gliomas (gliobastoma multiforme) using their brain MRI studies. To approach this problem, we first reduce the input features into a compressed representation, learned using an unsupervised 3D convolutional neural network based autoencoder which is trained to predict its own input. Once the most informative features are learned, they are further reduced in dimensionality using singular value decomposition. We then try a number of regression based machine learning methods on this reduced data. We observe the best mean squared error (MSE) of 125048 using K-nearest neighbours. Our observed results in terms of MSE are close to the state of the art methods as of writing this paper. However given the regressors’ correlation results and domain knowledge, we conclude that using brain MRI data alone in this framework is insufficient to produce predictions with high correlation.\n","date":1512432000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512432000,"objectID":"e0ee4ed1f20d8e9bddccdda64dd823ce","permalink":"https://trane293.github.io/project/ml-project/","publishdate":"2017-12-05T00:00:00Z","relpermalink":"/project/ml-project/","section":"project","summary":"Convolutional neural networks based autoencoders for generating low-dimensional representations of brain MRI scans.","tags":["deep learning","medical image analysis","convolutional neural network","computer vision"],"title":"Predicting Survival Time for Patients Diagnosed with Gliomas Using Compressed Representation of Brain MRI Scans","type":"project"},{"authors":["Anmol Sharma","Harman Preet Kaur","Both authors contributed equally to this work"],"categories":null,"content":"","date":1450483200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1450483200,"objectID":"026a633ea3a3e00a6f8bb1ab7cb06d7c","permalink":"https://trane293.github.io/publication/signature-conference/","publishdate":"2015-12-19T00:00:00Z","relpermalink":"/publication/signature-conference/","section":"publication","summary":"In this paper, a novel approach for the verification of offline handwritten signatures is proposed. Despite tremendous growth of digital technologies in the last 4 decades, the most used authentication method today remains to be handwritten signature. It is the most natural method of authenticating a person's identity as compared to other biometric and cryptographic forms of authentication. We propose a method for verifying the signatory's identity by using Zernike Moments as global shape descriptors. Zernike Moments are image moments that are rotation invariant. The moments are also orthogonal on a unit circle which ensures minimum redundancy between the features representing the object shape. The features extracted in our approach have a relatively low dimensionality as compared to other studies, while retaining high representation power of the moments. Moreover, the module developed using our approach was able to demonstrate high performance coupled with low computation times in testing phase, making it suitable for real time applications. Experiments show high overall performance of our approach with an equal error rate EER of 13.42% and area under the curve Az equal to 0.84 using 1564 images from the NFI SigComp2009 dataset.","tags":["machine learning","svm","artificial neural networks","natural language processing","document analysis"],"title":"Offline Handwritten Signature Verification using Zernike Moments","type":"publication"},{"authors":null,"categories":null,"content":"Masses are one of the important yet challenging signs of breast cancer, visible in the mammogram. The paper presents a novel mass classification scheme via the introduction of new feature selection algorithm along with feature extraction technique. To capture complete and complex shape, we propose Translation, Rotation, and Shift (TRS) invariant Zernike moments as global shape descriptor. The extracted features are further clubbed with texture information. The discriminating features are then selected with a new wrapper-based feature selection scheme combined with multi-objective Non-dominated Sorting Genetic Algorithm (NSGA-II) where three objectives are optimized simultaneously. The experiments show that the proposed three objective functions allow the NSGAII to reduce the feature dimensionality from 312 to four, while significantly outperforming classifiers trained on features with high dimensionality. With a set of four features, the method achieves the best area under the receiver characteristic curve of 0.95 and an accuracy of 89.89% using an artificial neural network for 270 randomly selected images from the DDSM database.\n","date":1444003200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1444003200,"objectID":"5d46ad87e13eeb320707d4733c234453","permalink":"https://trane293.github.io/project/mammogram-project/","publishdate":"2015-10-05T00:00:00Z","relpermalink":"/project/mammogram-project/","section":"project","summary":"Propose a new feature extraction and selection method using NSGA-II for classifying masses as benign or malignant.","tags":["machine learning","medical image analysis","artificial neural networks","svm","computer vision","optimization"],"title":"Automatic Characterization of Breast Masses using NSGA-II based Feature Selection","type":"project"},{"authors":["Anmol Sharma","Jagroop Singh"],"categories":null,"content":"","date":1387411200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1387411200,"objectID":"5fdf57b5f5fb4180cb2c3fe395b1a41c","permalink":"https://trane293.github.io/publication/image-conference/","publishdate":"2013-12-19T00:00:00Z","relpermalink":"/publication/image-conference/","section":"publication","summary":"Image denoising is the first preprocessing step dealing with image processing. In image denoising an image is processed using certain restoration techniques to remove induced noise which may creep in the image during acquisition, transmission or compression process. Examples of noise in an image can be Additive White Gaussian Noise (AWGN), Impulse Noise, etc. The goal of restoration techniques is to obtain an image that is as close to the original input image as possible. In this paper objective evaluation methods are used to judge the efficiency of different types of spatial domain filters applied to different noise models, with a quantitative approach. Performance of each filter is compared as they are applied on images affected by a wide variety of noise models. Conclusions are drawn in the end, about which filter is best suited for a number of noise models individually induced in an image, according to the experimental data obtained.","tags":["image processing","spatial filtering"],"title":"Image Denoising using Spatial Domain Filters: A Quantitative Study","type":"publication"}]